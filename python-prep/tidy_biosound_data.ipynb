{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Biosound data - Tidy up \n",
    "Prep the biosound data for use in the dashboard\n",
    "\n",
    "To run this in Pycharm you need to set up a kernel that points to the venv:\n",
    "`python -m ipykernel install --user --name=venv-osa`\n",
    "\n",
    "Also please note that the data files and folders in this notebook point to a specific path a local Google Drive shared folder. This will not work for others - the paths will need updating for each person."
   ],
   "id": "a3134b71ecef3d6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import data_wrangler as dw\n",
    "import os"
   ],
   "id": "1169eba9af59b9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up some initial things\n",
    "# Local path to the main \"Processed Data\" folder\n",
    "local_data_folder = ('/Users/michelle/Library/CloudStorage/GoogleDrive-michelle@waveformanalytics.com/.shortcut'\n",
    "                     '-targets-by-id/1QNPk7Z3Yb2uhHsHCf49pw7k_2-ivhIJg/Processed_Data')\n",
    "\n",
    "# config_file = os.path.join(local_data_folder, 'BioSound_Datasets_MapApp.csv')\n",
    "config_file = os.path.join(local_data_folder, 'BioSound_Datasets_MapApp_v1.csv')\n",
    "df_config = pd.read_csv(config_file)\n",
    "\n",
    "# Folder containing annotations data files\n",
    "annotations_folder = os.path.join(local_data_folder, 'Annotations')\n",
    "\n",
    "# Load the fish/annotations codes lookup table\n",
    "df_codes = pd.read_csv(\"../shiny/data/fish_codes.csv\")\n",
    "\n",
    "# Satellite water class data\n",
    "seascaper_folder = os.path.join(local_data_folder,\"All_SeascapeR\")\n",
    "\n",
    "# Output file path for the duckdb file \n",
    "db_file = os.path.join(local_data_folder, \"mbon.duckdb\")"
   ],
   "id": "963bb868eb51d740",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Take a look at the contents of the config file\n",
    "df_config"
   ],
   "id": "19149c11cccb168d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Annotations data\n",
    "\n",
    "### Prep Key West annotations\n",
    "Key west annotations are a bit different from the others. They're in a folder that contains several .txt files that need to first be merged and then copied into the same annotations folder as the other datasets."
   ],
   "id": "18eb470c9b63267e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "KW_ANNOTATIONS_FOLDER = os.path.join(local_data_folder, 'Annotations/key-west-original')\n",
    "KW_ANNOTATIONS_OUTFILE = os.path.join(local_data_folder, 'Annotations/KW_Annotations.csv')\n",
    "\n",
    "# Run the function from data_wrangler to convert to the regular annotations format and move the file to the same location as the rest of the annotation files\n",
    "dw.annotation_prep_kw_style(KW_ANNOTATIONS_FOLDER, KW_ANNOTATIONS_OUTFILE)"
   ],
   "id": "65f911d4af73e1bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prep May River annotations data\n",
    "\n",
    "May River annotations are also unique. They're stored in wide format in the \"Master_Manual....xlsx\" file. In this section we re-format so that it looks more like the Key West annotations and all the ship annotations (long-format)."
   ],
   "id": "712db8a1ccd3886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MR_ANNOTATIONS_FILE = os.path.join(local_data_folder, 'Annotations/may-river-original/Master_Manual_14M_2h_011119_071619.xlsx')\n",
    "MR_ANNOTATIONS_OUTFILE = os.path.join(local_data_folder, 'Annotations/MR_Annotations.csv')\n",
    "\n",
    "dw.annotation_prep_mr_style(MR_ANNOTATIONS_FILE, MR_ANNOTATIONS_OUTFILE, df_codes)"
   ],
   "id": "d896142dee754321",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Index data\n",
    "Prepare and load the data from the various acoustic index files and combine them all into a big dataframe. Also create a second dataframe that has all the same index values but normalized. "
   ],
   "id": "ca1131a1a20075e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# INDEX_DATA_FOLDER = os.path.join(local_data_folder, 'Revised_Indices_AllData_v2')\n",
    "INDEX_DATA_FOLDER = os.path.join(local_data_folder, 'Original_Indices_AllData_v1')\n",
    "\n",
    "df_aco0 = dw.prep_index_data(INDEX_DATA_FOLDER, normalize=False)\n",
    "df_aco_norm0 = dw.prep_index_data(INDEX_DATA_FOLDER, normalize=True)"
   ],
   "id": "82a583bf6d391e9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set time zones to local time\n",
    "dw.update_time_zone(df_aco0, df_config)\n",
    "dw.update_time_zone(df_aco_norm0, df_config)"
   ],
   "id": "d5f8c1b246f46c6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Add the annotation information to index dataframes\n",
    "\n",
    "Add new columns to the index dataframes for all possible indices for both presence and count."
   ],
   "id": "ee52bc70b8f87980"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_codes = np.unique(df_codes['code']).tolist()\n",
    "\n",
    "# Add new columns that are named using unique_fish_codes. These will become the \n",
    "df_aco = dw.add_new_columns(df_aco0, unique_codes)\n",
    "df_aco_norm = dw.add_new_columns(df_aco_norm0, unique_codes)"
   ],
   "id": "96303ef60a4b190e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_aco_anno = dw.add_annotations_to_df(df_aco, df_config, df_codes, annotations_folder)\n",
    "df_aco_norm_anno = dw.add_annotations_to_df(df_aco_norm, df_config, df_codes, annotations_folder)"
   ],
   "id": "9b02ffacf635acaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prep Seascaper Data\n",
   "id": "b25d917598690b12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_seascaper = dw.prep_seascaper_data(seascaper_folder, df_config)",
   "id": "6fa2e9c474254b11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create DuckDB\n",
    "\n",
    "Save the main pandas dataframes to a duckdb file."
   ],
   "id": "22fed6b3d5b8f4a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prep the dataframe list for export\n",
    "df_dict = {\n",
    "    \"t_aco2\": df_aco_anno,\n",
    "    \"t_aco_norm2\": df_aco_norm_anno,\n",
    "    \"t_seascaper\": df_seascaper\n",
    "}\n",
    "\n",
    "dw.duckdb_export(db_file, df_dict)"
   ],
   "id": "12293f4f6768505b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.shape(df_aco_anno)",
   "id": "ceffb997bbdbac1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db_file",
   "id": "81ec0748e7b00b3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "204852e340bd7310",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-osa",
   "language": "python",
   "name": "venv-osa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
